# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WKzBFFpY1htHQsRP0w-LCMts3UxlXSn6
"""

!pip install pandas scikit-learn shap
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
import shap

import pandas as pd
import numpy as np

np.random.seed(40)

num_records = 600

age = np.random.randint(16, 45, num_records)
gender = np.random.choice(['Male', 'Female', 'Other'], num_records, p=[0.4, 0.45, 0.03])
parent_education_level = np.random.choice(['High School', 'Associate Degree', 'Bachelor', 'Master', 'PhD'], num_records, p=[0.3, 0.25, 0.3, 0.1, 0.05])
household_income = np.random.choice(['Low', 'Medium', 'High'], num_records, p=[0.4, 0.6, 0.4])

GPA = np.round(np.random.uniform(4.0, 8.0, num_records), 4)
SAT_score = np.random.randint(600, 1800, num_records)
high_school_ranking = np.random.randint(2, 200, num_records)
extracurricular_activities = np.random.randint(1, 4, num_records)

previous_enrollment_attempts = np.random.randint(0, 3, num_records)
admission_type = np.random.choice(['Regular', 'Early Decision', 'Transfer'], num_records, p=[0.8, 0.5, 0.1])

enrolled = np.where(
    (GPA > 3.0) & (SAT_score > 1000) & (household_income != 'Low'),
    1,
    np.random.binomial(1, 0.3, num_records)
)

graduated = np.where(
    (enrolled == 1) & (GPA > 3.2) & (extracurricular_activities >= 1),
    1,
    np.random.binomial(1, 0.4, num_records)
)

data = pd.DataFrame({
    'age': age,
    'gender': gender,
    'parent_education_level': parent_education_level,
    'household_income': household_income,
    'GPA': GPA,
    'SAT_score': SAT_score,
    'high_school_ranking': high_school_ranking,
    'extracurricular_activities': extracurricular_activities,
    'previous_enrollment_attempts': previous_enrollment_attempts,
    'admission_type': admission_type,
    'enrolled': enrolled,
    'graduated': graduated
})

print(data.head())

data.to_csv('student_enrollment_data.csv', index=False)

from google.colab import files
files.download('student_enrollment_data.csv')

data = pd.read_csv('student_enrollment_data.csv')

data.head()
data.info()
data.isnull().sum()

features = data[['age', 'GPA', 'SAT_score', 'high_school_ranking', 'extracurricular_activities']]
target = data['enrolled']  # 'enrolled' as the target variable for predicting enrollment

features = data[['age', 'GPA', 'SAT_score', 'high_school_ranking', 'extracurricular_activities']]

target = data['enrolled']

print(data.columns)

print(features.head())
print(target.head())

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

print(data.isnull().sum())

data = data.dropna()

data = pd.get_dummies(data, drop_first=True)

scaler = StandardScaler()
data[['age', 'GPA', 'SAT_score', 'high_school_ranking', 'extracurricular_activities']] = scaler.fit_transform(
    data[['age', 'GPA', 'SAT_score', 'high_school_ranking', 'extracurricular_activities']])

features = data[['age', 'GPA', 'SAT_score', 'high_school_ranking', 'extracurricular_activities']]
target = data['enrolled']

X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)

model = LogisticRegression()

model.fit(X_train, y_train)

y_pred = model.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
print(f'Accuracy: {accuracy * 100:.2f}%')

print('Classification Report:')
print(classification_report(y_test, y_pred))

print('Confusion Matrix:')
print(confusion_matrix(y_test, y_pred))

import pickle
from google.colab import files

with open('student_enrollment_model.pkl', 'wb') as f:
    pickle.dump(model, f)

files.download('student_enrollment_model.pkl')

predictions_df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})

predictions_df.to_csv('predictions.csv', index=False)

files.download('predictions.csv')

print(data.head())

from sklearn.model_selection import GridSearchCV

# Define a parameter grid for logistic regression
param_grid = {
    'C': [0.1, 1, 10, 100],  # Regularization strength
    'solver': ['lbfgs', 'liblinear'],  # Solvers for optimization
    'max_iter': [100, 200, 300]  # Maximum number of iterations for convergence
}

# Initialize GridSearchCV with Logistic Regression
grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=5, scoring='accuracy')

# Fit the model with the training data
grid_search.fit(X_train, y_train)

# Print the best parameters found
print(f"Best Parameters: {grid_search.best_params_}")

# Get the best model from grid search
best_model = grid_search.best_estimator_

from sklearn.ensemble import RandomForestClassifier

# Initialize RandomForestClassifier
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)

# Train the model on the training data
rf_model.fit(X_train, y_train)

# Evaluate the Random Forest model
rf_y_pred = rf_model.predict(X_test)

# Evaluate performance
print(f'Random Forest Accuracy: {accuracy_score(y_test, rf_y_pred) * 100:.2f}%')
print('Classification Report (Random Forest):')
print(classification_report(y_test, rf_y_pred))

from sklearn.svm import SVC

# Initialize Support Vector Classifier
svm_model = SVC(kernel='linear', random_state=42)

# Train the model
svm_model.fit(X_train, y_train)

# Evaluate performance
svm_y_pred = svm_model.predict(X_test)
print(f'SVM Accuracy: {accuracy_score(y_test, svm_y_pred) * 100:.2f}%')
print('Classification Report (SVM):')
print(classification_report(y_test, svm_y_pred))

from sklearn.model_selection import cross_val_score

# Perform cross-validation with Logistic Regression
cv_scores = cross_val_score(LogisticRegression(), features, target, cv=5)

# Print the average cross-validation score
print(f'Cross-validation scores: {cv_scores}')
print(f'Mean cross-validation score: {cv_scores.mean():.2f}')

from sklearn.preprocessing import PolynomialFeatures

# Create polynomial features (degree=2)
poly = PolynomialFeatures(degree=2)
poly_features = poly.fit_transform(features)

# Re-train the model with polynomial features
model.fit(poly_features, target)

from sklearn.metrics import precision_score, recall_score, f1_score

# Calculate precision, recall, and F1-score
print(f'Precision: {precision_score(y_test, y_pred):.2f}')
print(f'Recall: {recall_score(y_test, y_pred):.2f}')
print(f'F1 Score: {f1_score(y_test, y_pred):.2f}')

from flask import Flask, request, jsonify
import pickle

# Load the model
with open('student_enrollment_model.pkl', 'rb') as f:
    model = pickle.load(f)

# Initialize Flask app
app = Flask(__name__)

# Endpoint for predictions
@app.route('/predict', methods=['POST'])
def predict():
    # Get the data from the POST request
    data = request.get_json()

    # Convert the data into a format the model can use
    features = np.array([data['age'], data['GPA'], data['SAT_score'], data['high_school_ranking']]).reshape(1, -1)

    # Make prediction
    prediction = model.predict(features)

    return jsonify({'prediction': prediction[0]})

if __name__ == '__main__':
    app.run(debug=True)

import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc

# Calculate ROC curve
fpr, tpr, thresholds = roc_curve(y_test, model.predict_proba(X_test)[:, 1])
roc_auc = auc(fpr, tpr)

# Plot ROC curve
plt.figure()
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic')
plt.legend(loc='lower right')
plt.show()